import os
import json
import numpy as np
import copy
import utils

from PIL import Image, ExifTags

from pycocotools.coco import COCO



class KAB():

    def __init__(self, class_map=None):
            self.image_info = []
            # Background is always the first class
            self.class_info = [{"source": "", "id": 0, "name": "BG"}]
            self.source_class_ids = {}

    def load_image(self, image_path):
            """Load the specified image and return as a [H,W,3] Numpy array."""
            image = Image.open(self.image_info[image_path]['path'])
            img_shape = np.shape(image)

            # load metadata
            exif = image._getexif()
            if exif:
                exif = dict(exif.items())
                # Rotate portrait images if necessary (274 is the orientation tag code)
                if 274 in exif:
                    if exif[274] == 3:
                        image = image.rotate(180, expand=True)
                    if exif[274] == 6:
                        image = image.rotate(270, expand=True)
                    if exif[274] == 8:
                        image = image.rotate(90, expand=True)

            # If has an alpha channel, remove it for consistency
            if img_shape[-1] == 4:
                image = image[..., :3]

            return np.array(image)

    def load_mask(self, image_path):
            """Load instance masks for the given image.

            Different datasets use different ways to store masks. This
            function converts the different mask format to one format
            in the form of a bitmap [height, width, instances].

            Returns:
            masks: A bool array of shape [height, width, instance count] with
                one mask per instance.
            class_ids: a 1D array of class IDs of the instance masks.
            """

            image_info = self.image_info[image_path]

            instance_masks = []
            class_ids = []
            annotations = self.image_info[image_path]["annotations"]
            # Build mask of shape [height, width, instance_count] and list
            # of class IDs that correspond to each channel of the mask.
            for annotation in annotations:
                class_id = self.map_source_class_id("taco.{}".format(annotation['category_id']))
                if class_id:
                    m = utils.annToMask(annotation, image_info["height"],image_info["width"])
                    # Some objects are so small that they're less than 1 pixel area
                    # and end up rounded out. Skip those objects.
                    if m.max() < 1:
                        continue
                    # Is it a crowd? If so, use a negative class ID.
                    if annotation['iscrowd']:
                        # Use negative class ID for crowds
                        class_id *= -1
                        # For crowd masks, annToMask() sometimes returns a mask
                        # smaller than the given dimensions. If so, resize it.
                        if m.shape[0] != image_info["height"] or m.shape[1] != image_info["width"]:
                            m = np.ones([image_info["height"], image_info["width"]], dtype=bool)
                    instance_masks.append(m)
                    class_ids.append(class_id)

    def load_image_gt(self, dataset, config, image_path):
        """Load and return ground truth data for an image (image, mask, bounding boxes).

        use_mini_mask: If False, returns full-size masks that are the same height
            and width as the original image. These can be big, for example
            1024x1024x100 (for 100 instances). Mini masks are smaller, typically,
            224x224 and are generated by extracting the bounding box of the
            object and resizing it to MINI_MASK_SHAPE.

        Returns:
        image: [height, width, 3]
        shape: the original shape of the image before resizing and cropping.
        class_ids: [instance_count] Integer class IDs
        bbox: [instance_count, (y1, x1, y2, x2)]
        mask: [height, width, instance_count]. The height and width are those
            of the image unless use_mini_mask is True, in which case they are
            defined in MINI_MASK_SHAPE.
        """
        # Load image and mask
        image = self.load_image(image_path)
        mask, class_ids = self.load_mask(image_path)
        original_shape = image.shape

        # Decide either to zoom in or use full image
        min_img_dim = min(image.shape[0], image.shape[1])
        ZOOM_IN = config.USE_OBJECT_ZOOM and min_img_dim > config.IMAGE_MAX_DIM and np.random.random()<config.ZOOM_IN_FREQ

        if not ZOOM_IN:
            image, window, scale, padding, crop = utils.resize_image(
                image,
                min_dim=config.IMAGE_MIN_DIM,
                min_scale=config.IMAGE_MIN_SCALE,
                max_dim=config.IMAGE_MAX_DIM,
                mode=config.IMAGE_RESIZE_MODE)
            mask = utils.resize_mask(mask, scale, padding, crop)
        else:
            image, mask, window, scale = utils.zoom_in(image, mask, config.IMAGE_MAX_DIM)


        # Note that some boxes might be all zeros if the corresponding mask got cropped out.
        # and here is to filter them out
        _idx = np.sum(mask, axis=(0, 1)) > 0
        mask = mask[:, :, _idx]
        class_ids = class_ids[_idx]
        # Bounding boxes. Note that some boxes might be all zeros
        # if the corresponding mask got cropped out.
        # bbox: [num_instances, (y1, x1, y2, x2)]
        bbox = utils.extract_bboxes(mask)

        # Active classes
        # Different datasets have different classes, so track the
        # classes supported in the dataset of this image.
        active_class_ids = np.zeros([dataset.num_classes], dtype=np.int32)
        source_class_ids = dataset.source_class_ids[dataset.image_info[image_path]["source"]]
        active_class_ids[source_class_ids] = 1

        # Resize masks to smaller size to reduce memory usage
        if use_mini_mask:
            mask = utils.minimize_mask(bbox, mask, config.MINI_MASK_SHAPE)

        # Image meta data
        image_meta = compose_image_meta(image_path, original_shape, image.shape,
                                        window, scale, active_class_ids)

        return image, image_meta, class_ids, bbox, mask

